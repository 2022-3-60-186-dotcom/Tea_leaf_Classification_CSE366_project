{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13654327,"sourceType":"datasetVersion","datasetId":8680609}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:12:18.322407Z","iopub.execute_input":"2025-11-14T17:12:18.323150Z","iopub.status.idle":"2025-11-14T17:12:19.672544Z","shell.execute_reply.started":"2025-11-14T17:12:18.323124Z","shell.execute_reply":"2025-11-14T17:12:19.671428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchinfo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:12:19.673510Z","iopub.execute_input":"2025-11-14T17:12:19.674023Z","iopub.status.idle":"2025-11-14T17:12:24.508041Z","shell.execute_reply.started":"2025-11-14T17:12:19.673992Z","shell.execute_reply":"2025-11-14T17:12:24.506971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport time\nimport random\nimport glob\nfrom tqdm.notebook import tqdm\nimport platform\nimport psutil\nimport PIL\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, auc\nfrom itertools import cycle\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models\nimport torch.optim as optim\n\n\n# --- SYSTEM AND PROJECT CONFIGURATION ---\nseed = 1\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Device:\", device)\n\ndata_dir = \"/kaggle/input/vggdataset/dataset\" \noutput_dir = \"/kaggle/working/processed-dataset-vgg16\"\ncheckpoints_path = \"/kaggle/working/checkpoints-vgg16\"\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(checkpoints_path, exist_ok=True)\n\n\ntrain_batch = 8\ntest_batch = 16\ntotal_class = 2 \nlearning_rate = 0.0001\ndecay = 1e-4\nepoch = 30       \npatience = 15\nIMG_SIZE = 64    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:12:24.509217Z","iopub.execute_input":"2025-11-14T17:12:24.509492Z","iopub.status.idle":"2025-11-14T17:12:33.982844Z","shell.execute_reply.started":"2025-11-14T17:12:24.509464Z","shell.execute_reply":"2025-11-14T17:12:33.981824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Data Loading and Splitting Logic ---\ndef load_split(split_dir):\n    file_paths, labels = [], []\n    for class_name in os.listdir(split_dir):\n        class_dir = os.path.join(split_dir, class_name)\n        if os.path.isdir(class_dir):\n            for image_name in os.listdir(class_dir):\n                file_paths.append(os.path.join(class_dir, image_name))\n                labels.append(class_name)\n    return pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n\ndata = load_split(data_dir)\n\n# 70/15/15 Split\ntrain_dataframe, temp_dataframe = train_test_split(data, test_size=0.30, stratify=data['label'], random_state=42)\nvalidation_dataframe, test_dataframe = train_test_split(temp_dataframe, test_size=0.50, stratify=temp_dataframe['label'], random_state=42)\n\nprint(f\"Original Data Counts:\\nTrain: {len(train_dataframe)}, Val: {len(validation_dataframe)}, Test: {len(test_dataframe)}\")\n\n# Data Preprocessing (Resizing images to 64x64)\ndef data_preprocess(df, split_name, size=(IMG_SIZE, IMG_SIZE), quality=90):\n    split_dir = os.path.join(output_dir, split_name)\n    os.makedirs(split_dir, exist_ok=True)\n    processed_file_paths = []\n    \n    # Only process if the directory is empty\n    if not os.path.exists(os.path.join(split_dir, df['label'].iloc[0])):\n        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {split_name}\"):\n            label_dir = os.path.join(split_dir, row['label'])\n            os.makedirs(label_dir, exist_ok=True)\n            try:\n                img = Image.open(row['file_path']).convert(\"RGB\")  \n                img = img.resize(size, Image.Resampling.LANCZOS)\n                save_path = os.path.join(label_dir, os.path.basename(row['file_path']))\n                img.save(save_path, optimize=True, quality=quality)\n                processed_file_paths.append(save_path)\n            except Exception as e:\n                pass\n        df['file_path'] = processed_file_paths\n    return df\n\ntrain_dataframe = data_preprocess(train_dataframe.copy(), \"train\")\nvalidation_dataframe = data_preprocess(validation_dataframe.copy(), \"val\")\ntest_dataframe = data_preprocess(test_dataframe.copy(), \"test\")\n\n\n# --- Data Loader Setup ---\nclass ImageDataset(Dataset):\n    def __init__(self, dataframe, transform):\n        self.dataframe = dataframe\n        self.transform = transform\n        unique_labels = sorted(self.dataframe['label'].unique())\n        self.label_map = {label: idx for idx, label in enumerate(unique_labels)}\n        self.class_names = [label for label, idx in self.label_map.items()]\n\n    def __len__(self): return len(self.dataframe)\n    def __getitem__(self, index):\n        img_path = self.dataframe.iloc[index]['file_path']\n        image = PIL.Image.open(img_path).convert('RGB')\n        label = self.label_map[self.dataframe.iloc[index]['label']]\n        return self.transform(image), label\n\ndef data_transform(train_df, val_df, test_df):\n    transform = transforms.Compose([\n        transforms.Resize(IMG_SIZE), transforms.CenterCrop(IMG_SIZE), transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    train_transform = transforms.Compose([\n        transforms.RandomRotation(degrees=15), transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.9, 1.1)), transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    train_dataset = ImageDataset(train_df, train_transform)\n    valid_dataset = ImageDataset(val_df, transform)\n    test_dataset = ImageDataset(test_df, transform)\n        \n    train_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, num_workers=0)\n    validation_dataloader = DataLoader(valid_dataset, batch_size=test_batch, shuffle=False, num_workers=0)\n    test_dataloader = DataLoader(test_dataset, batch_size=test_batch, shuffle=False, num_workers=0)\n    \n    return train_dataloader, validation_dataloader, test_dataloader, train_dataset.class_names\n\ntrain_dataloader, validation_dataloader, test_dataloader, class_names = data_transform(train_dataframe, validation_dataframe, test_dataframe)\nprint(f\"Class Names for reporting: {class_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:12:33.983884Z","iopub.execute_input":"2025-11-14T17:12:33.984616Z","iopub.status.idle":"2025-11-14T17:16:34.437976Z","shell.execute_reply.started":"2025-11-14T17:12:33.984583Z","shell.execute_reply":"2025-11-14T17:16:34.436957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- TRAIN MODEL FUNCTION ---\ndef train_model(model, criterion, optimizer, train_dataloader, validation_dataloader, num_epochs=30, early_stop_patience=15, checkpoints_path=\"checkpoints\"):\n    \n    if 'device' not in globals():\n        global device\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    val_loss_history = []\n    val_acc_history = []\n\n    best_val_acc = 0.0\n    consecutive_no_improvement = 0\n    \n    model_type = model.__class__.__name__\n    filepath = os.path.join(checkpoints_path, f\"{model_type}_best_model.pt\")\n    os.makedirs(checkpoints_path, exist_ok=True)\n    print(f\"Starting training on {device}...\")\n\n    for epoch_num in range(num_epochs):\n        # --- Training Phase ---\n        model.train()\n        running_loss = 0.0\n        correct_train = 0\n        total_train = 0\n\n        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n        for i, (inputs, labels) in progress_bar:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            _, predicted = torch.max(outputs, 1)\n            running_loss += loss.item() * inputs.size(0)\n            total_train += labels.size(0)\n            correct_train += (predicted == labels).sum().item()\n        \n        epoch_train_loss = running_loss / total_train\n\n        # --- Validation Phase ---\n        model.eval()\n        running_val_loss = 0.0\n        correct_val = 0\n        total_val = 0\n\n        with torch.no_grad():\n            for inputs, labels in validation_dataloader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                _, predicted = torch.max(outputs, 1)\n                running_val_loss += loss.item() * inputs.size(0)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n        epoch_val_loss = running_val_loss / total_val\n        epoch_val_acc = correct_val / total_val\n        val_loss_history.append(epoch_val_loss)\n        val_acc_history.append(epoch_val_acc)\n        \n        print(f'\\nEpoch {epoch_num+1}/{num_epochs} - Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.4f}')\n\n        # --- Early Stopping and Checkpoint Logic ---\n        if epoch_val_acc > best_val_acc:\n            best_val_acc = epoch_val_acc\n            best_epoch = epoch_num + 1\n            checkpoint = {\n                \"epoch\": epoch_num + 1,\n                \"model_weight\": model.state_dict(),\n                \"optimizer_state\": optimizer.state_dict(),\n                \"val_acc\": best_val_acc\n            }\n            torch.save(checkpoint, filepath)\n            print(f\"Best model saved at epoch {best_epoch} with validation accuracy: {best_val_acc:.4f}\")\n            consecutive_no_improvement = 0\n        else:\n            consecutive_no_improvement += 1\n            print(f\"EARLY STOP COUNTER {consecutive_no_improvement} / {early_stop_patience}\")\n\n        if consecutive_no_improvement >= early_stop_patience:\n            print(f\"Early stopping triggered. Training stopped.\")\n            break\n\n    return best_val_acc\n\n\n# --- VGG16 SCRATCH MODEL DEFINITION ---\nclass VGG16_Scratch(nn.Module):\n    def __init__(self, num_classes=2):\n        super(VGG16_Scratch, self).__init__()\n        \n        # VGG16 Feature Extractor with BatchNorm (improves stability)\n        self.features = self._make_layers([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], batch_norm=True)\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) \n        \n        # Classifier Layer with Dropout (Fixed for 2 classes)\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(0.5), \n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(0.5), \n            nn.Linear(4096, num_classes) # Correctly set to 2\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n    def _make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M': layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:16:34.439826Z","iopub.execute_input":"2025-11-14T17:16:34.440086Z","iopub.status.idle":"2025-11-14T17:16:34.457955Z","shell.execute_reply.started":"2025-11-14T17:16:34.440065Z","shell.execute_reply":"2025-11-14T17:16:34.457066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Starting VGG16 Scratch Model Training (Task 3) ---\")\n\nmodel_vgg16_scratch = VGG16_Scratch(num_classes=total_class).to(device)\n\n# --- CLASS WEIGHTS  ---\nclass_counts = train_dataframe['label'].value_counts()\nclass_labels = class_counts.index.tolist()\n\ntotal_samples = len(train_dataframe)\nclass_weights_list = [total_samples / class_counts[label] for label in class_labels]\nnormalized_weights = [w / sum(class_weights_list) * total_class for w in class_weights_list]\nclass_weights = torch.tensor(normalized_weights, dtype=torch.float).to(device)\nprint(f\"Calculated Class Weights for {class_labels}: {class_weights.cpu().numpy()}\")\n\n# --- Loss and Optimizer ---\ncriterion = nn.CrossEntropyLoss(weight=class_weights) \noptimizer_vgg16 = optim.Adam(model_vgg16_scratch.parameters(), lr=learning_rate, weight_decay=decay)\n\n# --- Start Training ---\nbest_vgg16_acc = train_model(\n    model_vgg16_scratch, \n    criterion, \n    optimizer_vgg16, \n    train_dataloader, \n    validation_dataloader, \n    num_epochs=epoch,\n    early_stop_patience=patience,\n    checkpoints_path=checkpoints_path\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T17:16:34.458875Z","iopub.execute_input":"2025-11-14T17:16:34.459136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- VGG16 FINAL EVALUATION SCRIPT ---\n\n# 1. Load the Best Model Checkpoint\nfilepath = os.path.join(checkpoints_path, \"VGG16_Scratch_best_model.pt\") \n\nmodel_vgg16_scratch_eval = VGG16_Scratch(num_classes=total_class).to(device)\n\ntry:\n    checkpoint = torch.load(filepath, map_location=device)\n    model_vgg16_scratch_eval.load_state_dict(checkpoint[\"model_weight\"])\n    print(f\"Model loaded successfully (Best epoch: {checkpoint.get('epoch', 'N/A')}, Val Acc: {checkpoint.get('val_acc', 'N/A'):.4f})\")\nexcept Exception as e:\n    print(f\"‚ùå ERROR: Failed to load VGG16 checkpoint. Check the path/filename, model architecture, and checkpoint key.\")\n    raise RuntimeError(\"Checkpoint loading failed. Evaluation cannot proceed.\")\n\n# 2. Evaluation Loop\ny_true, y_pred, y_pred_probs = [], [], []\nmodel_vgg16_scratch_eval.eval()\ntest_start_time = time.time()\n\nwith torch.no_grad():\n    for inputs, labels in test_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model_vgg16_scratch_eval(inputs)\n        \n        probs = F.softmax(outputs, dim=1)\n        _, predicted = torch.max(outputs, 1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n        y_pred_probs.extend(probs.cpu().numpy())\n\ntesting_time = time.time() - test_start_time\n\n# 3. Report All Metrics\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\ny_pred_probs = np.array(y_pred_probs)\n\nprint(\"\\n--- VGG16 Scratch Evaluation Report (Task 3) ---\")\n\n# Overall Accuracy\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Overall Test Accuracy: {accuracy:.4f}\")\n\n# Classification Report\nprint(\"\\n--- Classification Report ---\")\nprint(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\nprint(\"\\n--- Confusion Matrix ---\")\nprint(cm)\n\n# AUC Score (Binary Classification)\ntry:\n    # AUC for binary classification uses the probability of the positive class (index 1)\n    auc_score = roc_auc_score(y_true, y_pred_probs[:, 1]) \n    print(f\"\\nTest AUC: {auc_score:.4f}\")\nexcept Exception as e:\n    print(f\"\\nCould not calculate AUC. Error: {e}\")\n\nprint(f\"Total Testing Time: {testing_time:.2f} seconds\")\n\n\n# 4. ROC Curve Visualization\nplt.figure(figsize=(8, 6))\n# For 2 classes, index 1 is the positive class\nclass_probs = y_pred_probs[:, 1]\nfpr, tpr, _ = roc_curve(y_true, class_probs)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'VGG16 Scratch (AUC = {roc_auc:.4f})')\nplt.plot([0, 1], [0, 1], 'k--', lw=2, label='Chance')\nplt.title('ROC Curve - VGG16 Scratch (Task 3)')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}